{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Research questions\n",
    "\n",
    "Check if the data are parametric\n",
    "1. Independent\n",
    "2. Normal\n",
    "    Test for normality (1) (https://www.statology.org/normality-test-python/)\n",
    "        * Visual test -- histogram and QQ plot\n",
    "        * Shapiro-Wilk test\n",
    "        * KS\n",
    "3. Equal variances\n",
    "    Test for equal variance\n",
    "        * Levene's\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) \n",
    "\n",
    "1. (Visual Method) Create a histogram.\n",
    "\n",
    "    *from matplotlib import pyplot\n",
    "    *pyplot.hist(data)\n",
    "    *pyplot.show()\n",
    "\n",
    "If the histogram is roughly “bell-shaped”, then the data is assumed to be normally distributed.\n",
    "2. (Visual Method) Create a Q-Q plot.\n",
    "\n",
    "    *from statsmodels.graphics.gofplots import qqplot\n",
    "    *from matplotlib import pyplot\n",
    "    *qqplot(data, line='s')\n",
    "    *pyplot.show()\n",
    "\n",
    "If the points in the plot roughly fall along a straight diagonal line, then the data is assumed to be normally distributed.\n",
    "3. (Formal Statistical Test) Perform a Shapiro-Wilk Test.\n",
    "\n",
    "    from scipy.stats import shapiro\n",
    "    stat, p = shapiro(data)\n",
    "    print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "    alpha = 0.05 --- this is for the p-value test\n",
    "    if p > alpha:\n",
    "     print('Sample looks Gaussian (fail to reject H0)')\n",
    "    else:\n",
    "     print('Sample does not look Gaussian (reject H0)')\n",
    "     \n",
    "     *** If the p-value is greater than 0.05 then the data are normal, which means that it will have normal distribution with\n",
    "         Gaussian distribution (central limit theorem)\n",
    "         If the p-value is equal or less than 0.05 then the data is significant, which means that it will not follow the normal\n",
    "         distribution and will not behave as Gaussian distribution. \n",
    "\n",
    "    If the p-value of the test is greater than α = .05, then the data is assumed to be normally distributed.\n",
    "        4. (Formal Statistical Test) Perform a Kolmogorov-Smirnov Test.\n",
    "\n",
    "    If the p-value of the test is greater than α = .05, then the data is assumed to be normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the equal variance, use Levene's test:\n",
    "\n",
    "\n",
    "    *** ‘median’: recommended for skewed distributions.\n",
    "    *** ‘mean’: recommended for symmetric, moderate-tailed distributions.\n",
    "    *** ‘trimmed’: recommended for heavy-tailed distributions.\n",
    "    \n",
    "    import scipy.stats as stats\n",
    "    #Levene's test centered at the median\n",
    "    stats.levene(group1, group2, group3, center='median')\n",
    "\n",
    "    Output = (statistic=0.1798, pvalue=0.8364)\n",
    "\n",
    "    #Levene's test centered at the mean\n",
    "    stats.levene(group1, group2, group3, center='mean')\n",
    "\n",
    "    Output = (statistic=0.5357, pvalue=0.5914)\n",
    "    \n",
    "    #Levene's test centered at the trimmed\n",
    "    stats.levene(group1, group2, group3, center='trimmed')\n",
    "\n",
    "    Output = (statistic=0.5357, pvalue=0.5914)\n",
    "    \n",
    "    \n",
    "    *** Looking at the p-value is above 0.05 then the data fails to reject the null hypothesis, which means it will have equal\n",
    "        variances. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t-test:\n",
    "\n",
    "\n",
    "###############################################################################################################################\n",
    "    ### Two Sample t-test ###\n",
    "    import pandas as pd\n",
    "    from scipy.stats import ttest_ind\n",
    "\n",
    "    #create pandas DataFrame\n",
    "    df = pd.DataFrame({'method': ['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A',\n",
    "                                  'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B'],\n",
    "                       'score': [71, 72, 72, 75, 78, 81, 82, 83, 89, 91, 80, 81, 81,\n",
    "                                 84, 88, 88, 89, 90, 90, 91]})\n",
    "    \n",
    "    #view first five rows of DataFrame\n",
    "    df.head()\n",
    "\n",
    "      method  score\n",
    "    0      A     71\n",
    "    1      A     72\n",
    "    2      A     72\n",
    "    3      A     75\n",
    "    4      A     78\n",
    "\n",
    "    #define samples\n",
    "    group1 = df[df['method']=='A']\n",
    "    group2 = df[df['method']=='B']\n",
    "\n",
    "    #perform independent two sample t-test\n",
    "    ttest_ind(group1['score'], group2['score'])\n",
    "\n",
    "    Ttest_indResult(statistic=-2.6034304605397938, pvalue=0.017969284594810425)\n",
    "    \n",
    "    \n",
    "###############################################################################################################################\n",
    "    \n",
    "    \n",
    "    ### Welch's t-test (nonparametric) ###\n",
    "    \n",
    "    import pandas as pd\n",
    "    from scipy.stats import ttest_ind\n",
    "\n",
    "    #create pandas DataFrame\n",
    "    df = pd.DataFrame({'method': ['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A',\n",
    "                                  'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B'],\n",
    "                       'score': [71, 72, 72, 75, 78, 81, 82, 83, 89, 91, 80, 81, 81,\n",
    "                                 84, 88, 88, 89, 90, 90, 91]})\n",
    "\n",
    "    #define samples\n",
    "    group1 = df[df['method']=='A']\n",
    "    group2 = df[df['method']=='B']\n",
    "\n",
    "    #perform Welch's t-test\n",
    "    ttest_ind(group1['score'], group2['score'], equal_var=False)\n",
    "\n",
    "    Ttest_indResult(statistic=-2.603430460539794, pvalue=0.02014688617423973)\n",
    "    \n",
    "###############################################################################################################################    \n",
    "    ### Paired t-test\n",
    "    \n",
    "    import pandas as pd\n",
    "    from scipy.stats import ttest_rel\n",
    "\n",
    "    #create pandas DataFrame\n",
    "    df = pd.DataFrame({'method': ['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A',\n",
    "                                  'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B'],\n",
    "                       'score': [71, 72, 72, 75, 78, 81, 82, 83, 89, 91, 80, 81, 81,\n",
    "                                 84, 88, 88, 89, 90, 90, 91]})\n",
    "\n",
    "    #view first five rows of DataFrame\n",
    "    df.head()\n",
    "\n",
    "      method  score\n",
    "    0      A     71\n",
    "    1      A     72\n",
    "    2      A     72\n",
    "    3      A     75\n",
    "    4      A     78\n",
    "\n",
    "    #define samples\n",
    "    group1 = df[df['method']=='A']\n",
    "    group2 = df[df['method']=='B']\n",
    "\n",
    "    #perform independent two sample t-test\n",
    "    ttest_rel(group1['score'], group2['score'])\n",
    "\n",
    "    Ttest_relResult(statistic=-6.162045351967805, pvalue=0.0001662872100210469)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For correlation and linear assessment:\n",
    "    Parameteric: Pearson's R\n",
    "    Nonparametric: Spearman's Rank\n",
    "    \n",
    "    \n",
    "    ###############################################################################################\n",
    "    >>> import numpy as np\n",
    "    >>> import scipy.stats\n",
    "    \n",
    "    >>> x = np.arange(10, 20)\n",
    "    >>> y = np.array([2, 1, 4, 5, 8, 12, 18, 25, 96, 48])\n",
    "    \n",
    "    >>> scipy.stats.pearsonr(x, y)    # Pearson's r\n",
    "    (0.7586402890911869, 0.010964341301680832)\n",
    "    \n",
    "    >>> scipy.stats.spearmanr(x, y)   # Spearman's rho\n",
    "    SpearmanrResult(correlation=0.9757575757575757, pvalue=1.4675461874042197e-06)\n",
    "    \n",
    "    >>> scipy.stats.kendalltau(x, y)  # Kendall's tau\n",
    "    KendalltauResult(correlation=0.911111111111111, pvalue=2.9761904761904762e-05)\n",
    "\n",
    "    \n",
    "    ###############################################################################################\n",
    "    >>> import pandas as pd\n",
    "    >>> x = pd.Series(range(10, 20))\n",
    "    >>> x\n",
    "    0    10\n",
    "    1    11\n",
    "    2    12\n",
    "    3    13\n",
    "    4    14\n",
    "    5    15\n",
    "    6    16\n",
    "    7    17\n",
    "    8    18\n",
    "    9    19\n",
    "    dtype: int64\n",
    "    >>> y = pd.Series([2, 1, 4, 5, 8, 12, 18, 25, 96, 48])\n",
    "    >>> y\n",
    "    0     2\n",
    "    1     1\n",
    "    2     4\n",
    "    3     5\n",
    "    4     8\n",
    "    5    12\n",
    "    6    18\n",
    "    7    25\n",
    "    8    96\n",
    "    9    48\n",
    "    dtype: int64\n",
    "    >>> x.corr(y)                     # Pearson's r\n",
    "    0.7586402890911867\n",
    "    >>> y.corr(x)\n",
    "    0.7586402890911869\n",
    "    >>> x.corr(y, method='spearman')  # Spearman's rho\n",
    "    0.9757575757575757\n",
    "    >>> x.corr(y, method='kendall')   # Kendall's tau\n",
    "    0.911111111111111"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credit score analysis:\n",
    "    Discriminant analysis (LDA for linear) ***Scale each variable to have same mean and variance***\n",
    "    Logistic regression\n",
    "    Neural networks\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ways to fill the missing data:\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv(\"Complete_Titanic_Extended_Dataset.csv\")\n",
    "    df.info()\n",
    "    \n",
    "    ### To insert the mean value of each column into its missing rows:\n",
    "    df.fillna(df.mean(numeric_only=True).round(1), inplace=True)\n",
    "\n",
    "    # For median:\n",
    "    df.fillna(df.median(numeric_only=True).round(1), inplace=True)\n",
    "\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For useful websites:\n",
    "    https://www.kaggle.com/code/simonhchen/modeling-expected-loss-time-to-default\n",
    "    https://www.statology.org/\n",
    "    https://machinelearningmastery.com/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
